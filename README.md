### Requirements

```
conda env create -f environment.yml python=3.11
conda activate my_iccv_project
pip install -r requirements.txt

```

### How to Run
To execute the main script, use the following command:

python ./main.py \
    --subset "cifar10" \
    --arch-name "resnet18_modified" \
    --num-crop 5 \
    --mipc 10 \
    --ipc 10 \
    --stud-name "conv3" \
    --re-epochs 100 \
    --lam 0.0 \
    --n_iter 5 \
    --init_points 15

ðŸ”¹ Arguments Description
Argument	Description
--subset	Dataset to use (e.g., "cifar10")
--arch-name	Model architecture (e.g., "resnet18_modified")
--num-crop	Number of crops per image
--mipc	Maximum images per class
--ipc	Images per class
--stud-name	Student model name (e.g., "conv3")
--re-epochs	Number of re-training epochs
--lam	Regularization weight (e.g., 0.0)
--n_iter	Number of iterations for BO
--init_points	Initial number of points for BO

### Storage Format for Raw Datasets

All our raw datasets, including those like ImageNet-1K and CIFAR10, store their training and validation components in the following format to facilitate uniform reading using a standard dataset class method:

```
/path/to/dataset/
â”œâ”€â”€ 00000/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â”œâ”€â”€ image3.jpg
â”‚   â”œâ”€â”€ image4.jpg
â”‚   â””â”€â”€ image5.jpg
â”œâ”€â”€ 00001/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â”œâ”€â”€ image3.jpg
â”‚   â”œâ”€â”€ image4.jpg
â”‚   â””â”€â”€ image5.jpg
â”œâ”€â”€ 00002/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â”œâ”€â”€ image3.jpg
â”‚   â”œâ”€â”€ image4.jpg
â”‚   â””â”€â”€ image5.jpg
```
## ðŸ“‚ Code Structure

## ðŸ“‚ Project Structure

â”œâ”€â”€ main.py                 # Main script for training and evaluation
â”œâ”€â”€ argument.py             # Parses command-line arguments for main.py
â”œâ”€â”€ data/
â”‚   â””â”€â”€ additional_trained_models/   # Pretrained teacher model checkpoints
â”œâ”€â”€ Data/
â”‚   â”œâ”€â”€ dataset             # Directory for storing datasets
â”‚   â””â”€â”€ labelprompt/        # Label prompt text files for datasets
â”œâ”€â”€ synthesize/
â”‚   â”œâ”€â”€ main_0.py           # Selects initial images randomly
â”‚   â”œâ”€â”€ main_2.py           # Uses the teacher model to generate the final distilled dataset
â”‚   â”œâ”€â”€ main_GUIDE.py       # Creates a synthetic dataset via diffusion from initial images
â”‚   â”œâ”€â”€ models.py           # Model definitions for synthesis
â”‚   â”œâ”€â”€ utils.py            # Utility functions for the synthesis process
â”‚   â””â”€â”€ LocalStableDiffusion.py  # Diffusion process incorporating repulsion
â”œâ”€â”€ validation/ 
â”‚   â”œâ”€â”€ main_3.py           # Functions for evaluation
â”‚   â””â”€â”€ utils.py            # Utility functions for evaluation
